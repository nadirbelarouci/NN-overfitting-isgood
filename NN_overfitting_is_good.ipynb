{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Networks Overfitting is good",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadirbelarouci/NN-overfitting-isgood/blob/master/NN_overfitting_is_good.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ge1Ge7fBnRj5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D1Pi5grLRyBz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ALPHABET = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "INPUT_LAYER_SIZE = 32\n",
        "LABELS_SIZE = 27\n",
        "\n",
        "def prepare_data():\n",
        "  random_text = \"BASED ON YOUR INPUT GET A RANDOM ALPHA NUHE RANDOM STRING GENERATOR CREATES A SERIES OF AND LETTERS ALRBRFNKPZNJEBPCZ FHGDQPZLHE HELLO THERE HOW ARE YOU DOING TODAY AND BLA BLA BLA\"\n",
        "  \n",
        "  length = len(random_text)\n",
        "  \n",
        "  x_train = np.zeros((INPUT_LAYER_SIZE,length))\n",
        "  y_train = np.zeros(length)                   \n",
        "  \n",
        "  for i in range(length):\n",
        "    \n",
        "    x = [int(x) for x in bin(i)[2:]] \n",
        "    x = np.pad(x,(32-len(x),0),'constant')\n",
        "    \n",
        "    x_train[:,i] = x\n",
        "    y_train[i] = LABELS_SIZE-1 if random_text[i]==' ' else ord(random_text[i]) - 65\n",
        "   \n",
        "    \n",
        "  x_train = x_train.T\n",
        "  y_train = y_train.T \n",
        "  \n",
        "  return x_train, y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BWO1ARPnn8RZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f51c355a-535d-4386-d96c-cb9e6fc69bed"
      },
      "cell_type": "code",
      "source": [
        "x_train, y_train = prepare_data()\n",
        "print(x_train.shape,y_train.shape)\n",
        "print(np.min(y_train))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(180, 32) (180,)\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tO2c4hmaSfPE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(LABELS_SIZE, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OrrBht4qT6h2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train neural network\n",
        "score = 0.0\n",
        "while score < 1.0:\n",
        "  history = model.fit(x_train, y_train, epochs=5,verbose=False)\n",
        "  l = len(history.history['acc'])-1\n",
        "  score = history.history['acc'][l];"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pt-WPlxQUTwN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_train, y_train)\n",
        "print(score)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EJ8ODKZswW4h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "98f91fac-b6c1-44e3-8bda-85ac4839896c"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "    \n",
        "predictions = np.argmax(model.predict(x_train),axis=1) \n",
        "\n",
        "to_char = lambda x: \" \" if x == LABELS_SIZE-1 else chr(x+65)\n",
        "text = \"\".join(list(map(to_char, predictions)))\n",
        "\n",
        "print (text)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BASED ON YOUR INPUT GET A RANDOM ALPHA NUHE RANDOM STRING GENERATOR CREATES A SERIES OF AND LETTERS ALRBRFNKPZNJEBPCZ FHGDQPZLHE HELLO THERE HOW ARE YOU DOING TODAY AND BLA BLA BLA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MVcq2N1LukyW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
